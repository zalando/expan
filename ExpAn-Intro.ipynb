{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ExpAn: Experiment Analysis\n",
    "\n",
    "ExpAn is a Python library for the statistical analysis of randomised controlled trials (A/B tests). \n",
    "\n",
    "The functions are standalone and can be imported and used from within other projects, and from the command line.\n",
    "\n",
    "The library is Open Source, published under the MIT license here:\n",
    "\n",
    "[github.com/zalando/expan](https://github.com/zalando/expan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Installation\n",
    "\n",
    "To install the library:\n",
    "\n",
    "    $ pip install expan\n",
    "\n",
    "For more information, start with the [README.rst](https://github.com/zalando/expan/blob/master/README.rst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ExpAn Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `data.loaders` seperate details of data from library\n",
    "\n",
    "Loaders simply read the raw data (e.g. **`csv_fetcher.py`**) and return an `ExperimentData` object..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.experimentdata` is the interface between loaders and library\n",
    "\n",
    "The **`ExperimentData`** class abstracts the data structure such that we can have multiple loader modules that only need return this class, and none of our analysis modules need know anything about the file types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.experiment` provides the analysis functionality\n",
    "\n",
    "Users of ExpAn will spend most of their time with the **`Experiment`** class, which extends `ExperimentData` with analysis functions that all return a `Results` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.results` standardises all results\n",
    "\n",
    "All analyses on an **`Experiment`** (`feature_check`, `deltaKPI`, `SGA`, `trend`, etc.) return a **`Results`** object, standardising the structure, and allowing a series of such analyses to be kept in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.statistics` contains underlying statistical functions\n",
    "\n",
    "Such as: **`delta`**, **`bootstrap`**, **`chi-square`**. Used by higher-level `experiment` and `results` modules, and can be used directly from CLI, by passing in `Array`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.binning` keeps binning separate from data\n",
    "\n",
    "Instances of the **`Binning`** class (`NumericalBinning` and `CategoricalBinning`) represent a particular binning of some data, not the data itself, such that the same binning can then be applied to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## `core.utils` is a just a grabbag of stuff\n",
    "\n",
    "Pretty empty currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Details of Components\n",
    "\n",
    "Now we'll go into more details of the components, along with some examples of usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `data.loaders`\n",
    "\n",
    "Data loaders can be written as needed to handle different formats (CSV, Parquet, HDF5, etc) and different internal structures, so long as they return an `ExperimentData` object.\n",
    "\n",
    "Currently, only a simply CSV loader (`data.csv_fetcher`) has been implemented.\n",
    "\n",
    "We'll bypass this and work with synthesized data for now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpAn core init: v0.2.3\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "from os.path import dirname, join, realpath\n",
    "sys.path.insert(0, join(os.getcwd(), 'tests'))\n",
    "\n",
    "import numpy as np\n",
    "from tests_core.test_data import generate_random_data\n",
    "\n",
    "np.random.seed(0)\n",
    "data,metadata = generate_random_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>variant</th>\n",
       "      <th>normal_same</th>\n",
       "      <th>normal_shifted</th>\n",
       "      <th>feature</th>\n",
       "      <th>normal_shifted_by_feature</th>\n",
       "      <th>treatment_start_time</th>\n",
       "      <th>normal_unequal_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.487862</td>\n",
       "      <td>-0.616148</td>\n",
       "      <td>non</td>\n",
       "      <td>-1.088533</td>\n",
       "      <td>8</td>\n",
       "      <td>0.413510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>-1.125186</td>\n",
       "      <td>1.783682</td>\n",
       "      <td>has</td>\n",
       "      <td>1.167307</td>\n",
       "      <td>4</td>\n",
       "      <td>-3.212123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>0.388819</td>\n",
       "      <td>1.007539</td>\n",
       "      <td>non</td>\n",
       "      <td>-1.055948</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.986635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.173873</td>\n",
       "      <td>-0.889252</td>\n",
       "      <td>non</td>\n",
       "      <td>-0.152459</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>1.112634</td>\n",
       "      <td>0.434377</td>\n",
       "      <td>has</td>\n",
       "      <td>0.175988</td>\n",
       "      <td>8</td>\n",
       "      <td>0.719719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entity variant  normal_same  normal_shifted feature  \\\n",
       "0       0       A    -1.487862       -0.616148     non   \n",
       "1       1       B    -1.125186        1.783682     has   \n",
       "2       2       B     0.388819        1.007539     non   \n",
       "3       3       A    -1.173873       -0.889252     non   \n",
       "4       4       A     1.112634        0.434377     has   \n",
       "\n",
       "   normal_shifted_by_feature  treatment_start_time  normal_unequal_variance  \n",
       "0                  -1.088533                     8                 0.413510  \n",
       "1                   1.167307                     4                -3.212123  \n",
       "2                  -1.055948                     5                -5.986635  \n",
       "3                  -0.152459                     1                 0.469914  \n",
       "4                   0.175988                     8                 0.719719  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment': 'random_data_generation',\n",
       " 'primary_KPI': 'normal_shifted',\n",
       " 'source': 'simulated'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.experimentdata.ExperimentData\n",
    "\n",
    "The `ExperimentData` class abstracts the data format so that none of our analysis modules need know anything about the underlying data structure.\n",
    "\n",
    "In other words, this is the interface between fetching and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### metadata\n",
    "\n",
    "Comprises *at least*:\n",
    "\n",
    "* **`experiment`** - the name of the experiment (human-readable)\n",
    "* **`source`** - a string indicated the source(s)\n",
    "* **`primary_KPI`** - the Overall Evaluation Criteria *(not sure if this should be mandatory)*\n",
    "\n",
    "and optionally:\n",
    "\n",
    "* **`experiment_id`** - a machine-readable id for the experiment, if needed for your purposes\n",
    "* **`retrieval_time`** - timestamp of when the data is fetched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is here, in `ExperimentData`, that the fundamental distinction is made between KPIs and features.\n",
    "\n",
    "They have different storage requirements, and different possible applications in the analysis.\n",
    "\n",
    "Both are indexed by `entity`.\n",
    "\n",
    "**Features** are all data that does not change throughout the experiment.\n",
    "\n",
    "** KPIs** are all data that may be affected by the experiment. KPIs, therefore, may be indexed by `entity` and `date`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Constructing `ExperimentData`\n",
    "\n",
    "Now we want to put the data we loaded manually into an `ExperimentData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import expan\n",
    "\n",
    "expdata = expan.experimentdata.ExperimentData(data, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperimentData 'random_data_generation' with 2 features and 4 KPIs (primary: 'normal_shifted'), 10000 entities\n"
     ]
    }
   ],
   "source": [
    "print expdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The constructor automatically detects some features by name. All others are assumed to be KPIs...\n",
    "\n",
    "*TODO: check that this is still true?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: treatment_start_time, feature\n",
      "kpis    : normal_shifted_by_feature, normal_unequal_variance, normal_shifted, normal_same\n"
     ]
    }
   ],
   "source": [
    "print 'features: ' + ', '.join(expdata.feature_names)\n",
    "print 'kpis    : ' + ', '.join(expdata.kpi_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Features and KPIs are maintained as separate DataFrames\n",
    "\n",
    "This is for two main reasons:\n",
    "1. **Efficiency**: features never change over time, so need not be indexed as the KPIs will be\n",
    "2. **Usage**: KPIs must never be used for a Sub-group Analysis (primarily because of Simpson's paradox)\n",
    "\n",
    "However, the ExperimentData exposes both together (joined by `entity`) as the dynamic property `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>normal_shifted</th>\n",
       "      <th>normal_unequal_variance</th>\n",
       "      <th>normal_same</th>\n",
       "      <th>normal_shifted_by_feature</th>\n",
       "      <th>treatment_start_time</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity</th>\n",
       "      <th>variant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.616148</td>\n",
       "      <td>0.413510</td>\n",
       "      <td>-1.487862</td>\n",
       "      <td>-1.088533</td>\n",
       "      <td>8</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>B</th>\n",
       "      <td>1.783682</td>\n",
       "      <td>-3.212123</td>\n",
       "      <td>-1.125186</td>\n",
       "      <td>1.167307</td>\n",
       "      <td>4</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>B</th>\n",
       "      <td>1.007539</td>\n",
       "      <td>-5.986635</td>\n",
       "      <td>0.388819</td>\n",
       "      <td>-1.055948</td>\n",
       "      <td>5</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>A</th>\n",
       "      <td>-0.889252</td>\n",
       "      <td>0.469914</td>\n",
       "      <td>-1.173873</td>\n",
       "      <td>-0.152459</td>\n",
       "      <td>1</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>A</th>\n",
       "      <td>0.434377</td>\n",
       "      <td>0.719719</td>\n",
       "      <td>1.112634</td>\n",
       "      <td>0.175988</td>\n",
       "      <td>8</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                normal_shifted  normal_unequal_variance  normal_same  \\\n",
       "entity variant                                                         \n",
       "0      A             -0.616148                 0.413510    -1.487862   \n",
       "1      B              1.783682                -3.212123    -1.125186   \n",
       "2      B              1.007539                -5.986635     0.388819   \n",
       "3      A             -0.889252                 0.469914    -1.173873   \n",
       "4      A              0.434377                 0.719719     1.112634   \n",
       "\n",
       "                normal_shifted_by_feature  treatment_start_time feature  \n",
       "entity variant                                                           \n",
       "0      A                        -1.088533                     8     non  \n",
       "1      B                         1.167307                     4     has  \n",
       "2      B                        -1.055948                     5     non  \n",
       "3      A                        -0.152459                     1     non  \n",
       "4      A                         0.175988                     8     has  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expdata.metrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The constructor applies varies sanity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ExperimentData requires metadata: [source,experiment]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5fc1af22a77f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimentdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExperimentData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/rmuil/Projects/expan/expan/core/experimentdata.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, metrics, metadata, features, deepcopy)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[0mmissing_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmandatory_metadata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_metadata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ExperimentData requires metadata: ['\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_metadata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m']'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'primary_KPI'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'primary_KPI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkpis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ExperimentData requires metadata: [source,experiment]'"
     ]
    }
   ],
   "source": [
    "expan.experimentdata.ExperimentData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"ExperimentData requires the primary_KPI ('normal_shifted') to be present in the KPIs.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-bf853237232c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mborn_to_fail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'normal_shifted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mexpan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimentdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExperimentData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mborn_to_fail\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/rmuil/Projects/expan/expan/core/experimentdata.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, metrics, metadata, features, deepcopy)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'primary_KPI'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'primary_KPI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkpis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \t\t\traise KeyError('ExperimentData requires the primary_KPI (\\'{}\\') to be present in the KPIs.'.format(\n\u001b[1;32m--> 113\u001b[1;33m \t\t\t\tself.metadata['primary_KPI']))\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariant_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"ExperimentData requires the primary_KPI ('normal_shifted') to be present in the KPIs.\""
     ]
    }
   ],
   "source": [
    "born_to_fail = data.drop('normal_shifted', axis=1)\n",
    "\n",
    "expan.experimentdata.ExperimentData(born_to_fail, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.experiment.Experiment (extends ExperimentData)\n",
    "\n",
    "This class represents the experiment to be analysed.\n",
    "\n",
    "It extends the `ExperimentData` class, adding analysis functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Constructing `Experiment` \n",
    "\n",
    "The `Experiment` class has one more requirement for metadata:\n",
    "\n",
    "* **`baseline_variant`** - indicating which of the variants is to be considered baseline (a.k.a. control)\n",
    "\n",
    "In our data we have two variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A', 'B'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expdata.variant_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, with 'A' as the baseline variant, we construct an `Experiment` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'random_data_generation' with 2 features and 4 KPIs (primary: 'normal_shifted'), 10000 entities\n",
      " 2 variants: *A*, B\n"
     ]
    }
   ],
   "source": [
    "exp = expan.experiment.Experiment('A', data, metadata)\n",
    "\n",
    "print exp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "TODO: Will add a constructor to go directly from ExperimentData... https://github.com/zalando/expan/issues/8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now we can start analysing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Let's start with a single DeltaKPI of orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('once',UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline_variant': 'A', 'version': '0.2.3', 'warnings': {'Experiment.delta': UserWarning('Sample variances differ too much to assume that population variances are equal.',)}, 'errors': {}, 'source': 'simulated', 'experiment': 'random_data_generation', 'primary_KPI': 'normal_shifted'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>subgroup_metric</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pctile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_unequal_variance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaN</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.000000</td>\n",
       "      <td>3892.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.035216</td>\n",
       "      <td>-0.242713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.035216</td>\n",
       "      <td>0.274130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.021275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             value  \\\n",
       "variant                                                                          A   \n",
       "metric                  subgroup_metric subgroup statistic     pctile                \n",
       "normal_unequal_variance -               NaN      sample_size   NaN     6108.000000   \n",
       "                                                 uplift        NaN        0.000000   \n",
       "                                                 uplift_pctile 2.5       -0.035216   \n",
       "                                                               97.5       0.035216   \n",
       "                                                 variant_mean  NaN        0.005567   \n",
       "\n",
       "                                                                                    \n",
       "variant                                                                          B  \n",
       "metric                  subgroup_metric subgroup statistic     pctile               \n",
       "normal_unequal_variance -               NaN      sample_size   NaN     3892.000000  \n",
       "                                                 uplift        NaN        0.015708  \n",
       "                                                 uplift_pctile 2.5       -0.242713  \n",
       "                                                               97.5       0.274130  \n",
       "                                                 variant_mean  NaN        0.021275  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_delta = exp.delta(['normal_unequal_variance'])\n",
    "print res_delta.metadata\n",
    "res_delta.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Several things to see here.\n",
    "\n",
    "### First, the warning\n",
    "\n",
    "The analysis functions will emit warnings for known gotchas and strange things in the data.\n",
    "\n",
    "*NB: currently, warnings aren't emitted but stored directly in Results. Will be changed: https://github.com/zalando/expan/issues/7*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Second, the overkill output\n",
    "\n",
    "This is the standardised `Result` structure. It seems redundant for a single DeltaKPI, but we will see later on why it is so convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What are our actual values:\n",
    "The output to note here is:\n",
    "\n",
    "* **`variant_mean` for both variants**: the individual means of each variant, for each metric\n",
    " * here, `0.005567` and `0.021275`\n",
    "\n",
    "* **`uplift` for variant `B`**: this is simply the difference (delta) between the `variant_mean`s of `A` and `B`\n",
    " * here: an uplift of ~`0.016` in the KPI `normal_unequal_variance`\n",
    "\n",
    "* **`uplift_pctile` for variant `B`**: this portrays the likely distribution of the uplift\n",
    " * In this case, the percentiles give the 95% confidence intervals (the 97.5% and 2.5% percentiles), indicating that:\n",
    " * the uplift may vary between `-0.24` and `+0.27`\n",
    " * we encode this distribution as two percentiles because it gives us flexibility in the future for various one-sided, two-sided, and partial-distribution outputs, also allowing Bayesian analyses on these outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Metadata:\n",
    "Also note that metadata from the `Experiment` is preserved in the `Result`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Using Bootstrapping:\n",
    "\n",
    "The warning we got gives us concern that our normal assumption is violated. This suggests using a non-parametric approach, like bootstrapping.\n",
    "\n",
    "We simply tell the `delta` function not to assume normality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>subgroup_metric</th>\n",
       "      <th>subgroup</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pctile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_shifted</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">NaN</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.000000</td>\n",
       "      <td>3892.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.990986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.950993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.033908</td>\n",
       "      <td>1.031373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.005515</td>\n",
       "      <td>0.985470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    value  \\\n",
       "variant                                                                 A   \n",
       "metric         subgroup_metric subgroup statistic     pctile                \n",
       "normal_shifted -               NaN      sample_size   NaN     6108.000000   \n",
       "                                        uplift        NaN        0.000000   \n",
       "                                        uplift_pctile 2.5       -0.034607   \n",
       "                                                      97.5       0.033908   \n",
       "                                        variant_mean  NaN       -0.005515   \n",
       "\n",
       "                                                                           \n",
       "variant                                                                 B  \n",
       "metric         subgroup_metric subgroup statistic     pctile               \n",
       "normal_shifted -               NaN      sample_size   NaN     3892.000000  \n",
       "                                        uplift        NaN        0.990986  \n",
       "                                        uplift_pctile 2.5        0.950993  \n",
       "                                                      97.5       1.031373  \n",
       "                                        variant_mean  NaN        0.985470  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.delta(['normal_shifted'], assume_normal=False).df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We don't notice it here, but bootstrapping takes considerably longer, so if we do not have an explicit reason to use it, it is almost always better to leave it off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiple metrics at once:\n",
    "\n",
    "We don't actually have to analyse the metrics one at a time: the `delta` function (and most others) will by default operate on all KPIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.width', 80)\n",
    "pd.set_option('display.precision', 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = exp.delta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>statistic</th>\n",
       "      <th>pctile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_unequal_variance</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.0000000</td>\n",
       "      <td>3892.0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0000000</td>\n",
       "      <td>0.0157081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.0352156</td>\n",
       "      <td>-0.2427134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.0352156</td>\n",
       "      <td>0.2741295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0055671</td>\n",
       "      <td>0.0212752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_shifted</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.0000000</td>\n",
       "      <td>3892.0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0000000</td>\n",
       "      <td>0.9909859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.0352283</td>\n",
       "      <td>0.9509697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.0352283</td>\n",
       "      <td>1.0310020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.0055154</td>\n",
       "      <td>0.9854704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_same</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.0000000</td>\n",
       "      <td>3892.0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0000000</td>\n",
       "      <td>-0.0330525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.0355484</td>\n",
       "      <td>-0.0732398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.0355484</td>\n",
       "      <td>0.0071347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0252194</td>\n",
       "      <td>-0.0078331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">normal_shifted_by_feature</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>NaN</th>\n",
       "      <td>6108.0000000</td>\n",
       "      <td>3892.0000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uplift</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0000000</td>\n",
       "      <td>0.4622819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">uplift_pctile</th>\n",
       "      <th>2.5</th>\n",
       "      <td>-0.0351568</td>\n",
       "      <td>0.4204035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5</th>\n",
       "      <td>0.0351568</td>\n",
       "      <td>0.5041603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variant_mean</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.0164650</td>\n",
       "      <td>0.4787469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       value              \n",
       "variant                                                    A             B\n",
       "metric                    statistic     pctile                            \n",
       "normal_unequal_variance   sample_size   NaN     6108.0000000  3892.0000000\n",
       "                          uplift        NaN        0.0000000     0.0157081\n",
       "                          uplift_pctile 2.5       -0.0352156    -0.2427134\n",
       "                                        97.5       0.0352156     0.2741295\n",
       "                          variant_mean  NaN        0.0055671     0.0212752\n",
       "normal_shifted            sample_size   NaN     6108.0000000  3892.0000000\n",
       "                          uplift        NaN        0.0000000     0.9909859\n",
       "                          uplift_pctile 2.5       -0.0352283     0.9509697\n",
       "                                        97.5       0.0352283     1.0310020\n",
       "                          variant_mean  NaN       -0.0055154     0.9854704\n",
       "normal_same               sample_size   NaN     6108.0000000  3892.0000000\n",
       "                          uplift        NaN        0.0000000    -0.0330525\n",
       "                          uplift_pctile 2.5       -0.0355484    -0.0732398\n",
       "                                        97.5       0.0355484     0.0071347\n",
       "                          variant_mean  NaN        0.0252194    -0.0078331\n",
       "normal_shifted_by_feature sample_size   NaN     6108.0000000  3892.0000000\n",
       "                          uplift        NaN        0.0000000     0.4622819\n",
       "                          uplift_pctile 2.5       -0.0351568     0.4204035\n",
       "                                        97.5       0.0351568     0.5041603\n",
       "                          variant_mean  NaN        0.0164650     0.4787469"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.df.reset_index(['subgroup','subgroup_metric'],drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.results.Result\n",
    "\n",
    "The `Result` class standardises the results of an analysis such as `feature_check`, `deltaKPI`, `SGA`, `trend`, or a series of such analyses.\n",
    "\n",
    "Currently, this class **has-a** pandas `DataFrame`, but could in the future be implemented so that it **is-a** `DataFrame`, with the addition of metadata.\n",
    "\n",
    "Above and beyond the structure it enforces, this class basically consists of:\n",
    "\n",
    "1. Helper functions to ease indexing\n",
    "\n",
    "1. Functions to restructure output of underlying functions into a `Result` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'means'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-2732f1515a5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#TODO: need to fix this https://github.com/zalando/expan/issues/9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/rmuil/Projects/expan/expan/core/results.pyc\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    225\u001b[0m                         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'metric'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'subgroup_metric'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \t\t)\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Results' object has no attribute 'means'"
     ]
    }
   ],
   "source": [
    "#TODO: need to fix this https://github.com/zalando/expan/issues/9\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#results.means()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results.statistic('delta', 'sample_size', 'normal_shifted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#results.bounds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pp\n",
    "import seaborn\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Basing everything on pandas `DataFrame` gives us a lot for free:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#results.bounds().loc[['normal_same','normal_shifted'],:].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sub-Group Analysis (SGA)\n",
    "\n",
    "Let's look at orders, net sales, and PCII but broken down by CLV subgroups..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sga_results = exp.sga(['feature'],['normal_shifted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',200)\n",
    "#Note: this if using HTML output, truncation causes the index to be screwed up\n",
    "sga_results.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Trend Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "#Will show time-domain analysis later when I load time data\n",
    "# Create time column. TODO: Do this nicer\n",
    "exp.kpis['time_since_treatment'] = exp.features['treatment_start_time']\n",
    "# Make time part of index\n",
    "exp.kpis.set_index('time_since_treatment',append=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 120)\n",
    "res_trend = exp.trend(['normal_shifted'])\n",
    "res_trend.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.binning\n",
    "\n",
    "More complicated than you'd think.\n",
    "\n",
    "Defines a Binning class that represents a particular binning of a data, such that the same binning can then be applied to unseen data.\n",
    "\n",
    "Numerical and Categorical Binnings are defined.\n",
    "\n",
    "Tries to handle skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a = exp.features.xs(('A'),level=('variant'))\n",
    "b = exp.features.xs(('B'),level=('variant'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Now we create the binning\n",
    "\n",
    "This simply determines the thresholds appropriate for creating the requested number of bins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import core.binning as binning\n",
    "binning.dbg_lvl=0\n",
    "\n",
    "bins = binning.create_binning(a.loc[:,'treatment_start_time'])\n",
    "\n",
    "print bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### We can *apply* this binning to the same data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "a_bins = bins.label(a.treatment_start_time)\n",
    "\n",
    "pd.DataFrame(a_bins).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### And we can *apply* it to different data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b_bins = bins.label(b.treatment_start_time)\n",
    "\n",
    "pd.DataFrame(b_bins).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that there is a hidden 'catch-all' bin...\n",
    "\n",
    "This is implemented as the last entry in the arrays, making indexing very easy: an unknown bin is always -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bins.uppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bins._uppers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Bin labels can be arbitrarily formatted:\n",
    "\n",
    "Without running the binning algorithm on the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print bins.__str__('{conditions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print bins.__str__('{iter.uppercase}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print bins.__str__('{iter.uppercase}: From {lo:.2f} \\t To {up:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.statistics\n",
    "\n",
    "Here the underlying statistical functions are implemented. These are used by the higher-level `experiment` and `results` modules, and can indeed be used directly by passing in NumPy `Array`s.\n",
    "\n",
    "The more interesting functions are:\n",
    "\n",
    "### `bootstrap`\n",
    "\n",
    "Bootstraps the Confidence Intervals for a particular function comparing two samples. NaNs are ignored (discarded before calculation).\n",
    "\n",
    "This function, as well as others such as `normal_sample_difference`, and `delta`, take as input a list of percentiles, and return the values corresponding to those percentiles. This implementation is very general, allowing us to use the same functions for one-sided as well as two-sided tests, as well as more exactly recreating an output distribution (e.g. if we want to graphically depict more than 95% confidence intervals).\n",
    "\n",
    "### `delta`\n",
    "\n",
    "Uses either bootstrap or standard normal assumptions to compute the difference between two arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## core.utils\n",
    "\n",
    "A `commons` module: a grabbag of stuff we use all over the place.\n",
    "\n",
    "Pretty empty currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# That's it! Try it out for yourself:\n",
    "\n",
    "\n",
    "[github.com/zalando/expan](https://github.com/zalando/expan)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
